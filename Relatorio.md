# Relat√≥rio

## Quais s√£o os principais campos de dados extra√≠dos dos im√≥veis?

### Campos que foram extra√≠dos dos im√≥veis
- **`codigo`**: C√≥digo √∫nico do im√≥vel (ex: "878771259229-0")
- **`numero_item`**: N√∫mero do item no leil√£o (ex: "533")
- **`titulo`**: Nome do empreendimento (ex: "SAO PAULO - RESIDENCIAL CEREJEIRAS")
- **`endereco`**: Endere√ßo completo
- **`bairro`**: Bairro extra√≠do automaticamente
- **`tipo_imovel`**: "Apartamento" ou "Casa"
- **`area`**: √Årea √∫til em m¬≤ (ex: "70,86 m¬≤")
- **`quartos`**: N√∫mero de quartos (ex: "2 quartos")
- **`valor`**: Valor de venda (ex: "R$ 197.857,57")
- **`modalidade`**: "Leil√£o" ou "Venda Direta"

## Como a cad√™ncia de requisi√ß√µes √© gerenciada pelo script?

### Estrat√©gias Implementadas

1. **Rate Limiting**: 6 reqs por segundo
   ```python
   @sleep_and_retry
   @limits(calls=6, period=1)  # at√© 6 req/segundo
   def _post(self, url: str, data: dict) -> requests.Response:
   ```

2. **Delay Manual**: 0.5 segundos entre p√°ginas
   ```python
   self.delay_between_requests = 0.5  # segundos
   # No loop principal:
   time.sleep(self.delay_between_requests)
   ```

3. **Backoff Exponencial**: 0.5-6 segundos em falhas
   ```python
   @retry(reraise=True,
          stop=stop_after_attempt(5),
          wait=wait_exponential(multiplier=0.5, min=0.5, max=6),
          retry=retry_if_exception_type(RequestException))
   ```

4. **Jitter Aleat√≥rio**: 0.5-1.5 segundos na renova√ß√£o de sess√£o
   ```python
   def _refresh_session(self):
       # jitter aleat√≥rio antes de reabrir
       time.sleep(0.5 + random.random())
       self._init_session()
   ```

5. **Retry Autom√°tico**: 5 tentativas no m√°ximo por requisi√ß√£o
   ```python
   @retry(reraise=True,
          stop=stop_after_attempt(5),  # 5 tentativas m√°ximo
          retry=retry_if_exception_type(RequestException))
   ```

## Quais outras barreiras anti-scraping tive que lidar no c√≥digo?

### Principais Barreiras Contornadas

1. **Bot Manager Radware**: indentifica e renova automaticamente a sess√£o.
   ```python
   def _is_captcha(self, text: str) -> bool:
       t = text[:2048].lower()
       return ("radware bot manager" in t) or ("captcha" in t and "radware" in t)
   ```

2. **User-Agent Fingerprinting**: User-Agents gerados randomicamente.
   ```python
   from fake_useragent import UserAgent
   self.ua = UserAgent()
   ua = self.ua.random  # Novo UA a cada sess√£o
   ```

3. **Headers HTTP**: Headers que simulam um navegador padr√£o.
   ```python
   s.headers.update({
       "User-Agent": ua,
       "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
       "Accept-Language": "pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7",
       "Connection": "keep-alive",
       "Referer": self.search_url,
       "Origin": BASE_URL
   })
   ```

4. **Cookies e Sess√£o**: Persist√™ncia de estado.
   ```python
   def _init_session(self):
       s = requests.Session()
       s.get(self.search_url, timeout=30)  # Primeira visita para cookies
       self.session = s
   ```

5. **HTML Malformado**: REGEX para padr√µes quebrados
   ```python
   # HTML quebrado: <option value='260'>MANAUS<br><option value='269'>NOVA OLINDA
   option_pattern = r"<option value='([^']+)'>([^<]+)"
   matches = re.findall(option_pattern, html)
   ```

6. **Endpoints Fragmentados**: Fluxo multi-etapas para diferentes estados da p√°gina.
   ```python
   URL_CIDADES = f"{SISTEMA}/carregaListaCidades.asp"    # 1. C√≥digo da cidade
   URL_BAIRROS = f"{SISTEMA}/carregaListaBairros.asp"    # 2. Lista bairros
   URL_PESQUISA = f"{SISTEMA}/carregaPesquisaImoveis.asp" # 3. Inicia pesquisa
   URL_LISTA = f"{SISTEMA}/carregaListaImoveis.asp"      # 4. Carrega p√°ginas
   ```

7. **Campos Hidden**: Extrai automaticamente campos din√¢micos.
   ```python
   # hdnImov1, hdnImov2, hdnImov3... para pagina√ß√£o
   for inp in soup.find_all('input'):
       if iid.startswith('hdnImov'):
           idx = int(iid.replace('hdnImov', ''))
           ids_por_pagina[idx] = inp.get('value')
   ```

8. **Jitter Temporal**: Delays aleat√≥rios para melhorar a cad√™ncia das requisi√ß√µes.
   ```python
   def _refresh_session(self):
       time.sleep(0.5 + random.random())  # 0.5-1.5s aleat√≥rio
       self._init_session()
   ```

## Lista de features extra√≠das dos im√≥veis

- Identifica√ß√£o: `codigo`, `numero_item`, `titulo`
- Localiza√ß√£o: `endereco`, `bairro`
- Caracter√≠sticas: `tipo_imovel`, `area`, `quartos`
- Comerciais: `valor`, `modalidade`

## Quais s√£o os principais desafios que tive que resolver com esse sistema?

### Como cada desafio t√©cnico foi resolvido:

1. **Sistema Anti-Bot Radware**: Detec√ß√£o autom√°tica e renova√ß√£o de sess√£o
   ```python
   def _is_captcha(self, text: str) -> bool:
       t = text[:2048].lower()
       return ("radware bot manager" in t) or ("captcha" in t and "radware" in t)
   
   if self._is_captcha(resp.text):
       logger.warning("CAPTCHA detectado. Renovando sess√£o.")
       self._refresh_session()
       raise RequestException("captcha")
   ```

2. **Fluxo Multi-Etapas**: 4 endpoints sequenciais simulando navega√ß√£o humana
   ```python
   # 1) Descobrir c√≥digo da cidade
   cod_cidade = self._obter_codigo_cidade(self.estado, self.cidade)
   # 2) Obter bairros dispon√≠veis
   self._obter_bairros(self.estado, cod_cidade)
   # 3) Iniciar pesquisa e extrair metadados
   html_inicio = self._iniciar_pesquisa(self.estado, cod_cidade)
   # 4) Iterar p√°ginas via endpoint
   frag = self._carregar_pagina_fragmento(ids)
   ```

3. **HTML Malformado**: Parsing robusto com regex especializados
   ```python
   # HTML quebrado: <option value='260'>MANAUS<br><option value='269'>
   option_pattern = r"<option value='([^']+)'>([^<]+)"
   matches = re.findall(option_pattern, html)
   # M√∫ltiplas estrat√©gias de parsing
   endereco_patterns = [
       r'((?:RUA|AVENIDA|AV|ALAMEDA)[^,]+(?:,[^,]+)*?)(?:,\s*,|$)',
       r'N√∫mero do im√≥vel:\s*[0-9\-]+\s*(.+?)(?:\s*$|despesas)',
   ]
   ```

4. **Pagina√ß√£o Complexa**: Extra√ß√£o de IDs hidden din√¢micos (`hdnImov1..N`)
   ```python
   def _extrair_ids_e_paginacao(self, html: str):
       ids_por_pagina: Dict[int, str] = {}
       for inp in soup.find_all('input'):
           iid = inp.get('id') or ''
           if iid.startswith('hdnImov'):
               idx = int(iid.replace('hdnImov', ''))
               ids_por_pagina[idx] = (inp.get('value') or '').strip()
       return ids_por_pagina, total_paginas, total_registros
   ```

5. **Mapeamento de Cidades**: Consulta din√¢mica + algoritmos de matching
   ```python
   def _obter_codigo_cidade(self, estado: str, nome_cidade: str):
       # Busca exata primeiro
       if alvo in city_options:
           return city_options[alvo]
       # Busca parcial (cont√©m)
       for city_name, city_code in city_options.items():
           if alvo in city_name:
               return city_code
       # Fallback para overrides conhecidos
       override = CITY_CODE_OVERRIDES.get((estado, alvo))
       if override:
           return override
   ```

6. **Detec√ß√£o de Bairros**: Lista oficial + padr√µes lingu√≠sticos
   ```python
   def detect_bairro_from_endereco(self, endereco):
       # Usar lista oficial de bairros
       for bairro in self.bairros_disponiveis:
           if bairro in endereco_upper:
               return bairro
       # Padr√µes lingu√≠sticos
       prefixos_bairro = ['VILA ', 'CIDADE ', 'JARDIM ', 'PARQUE ']
       for prefixo in prefixos_bairro:
           if prefixo in endereco_upper:
               return endereco_upper[start_pos:].split(',')[0]
   ```

7. **Rate Limiting Agressivo**: M√∫ltiplas camadas de controle de velocidade
   ```python
   @sleep_and_retry
   @limits(calls=6, period=1)  # 6 req/segundo
   @retry(stop=stop_after_attempt(5),
          wait=wait_exponential(multiplier=0.5, min=0.5, max=6))
   def _post(self, url: str, data: dict):
       # + delay manual entre p√°ginas
       time.sleep(self.delay_between_requests)
   ```

8. **Limpeza de Dados**: Remo√ß√£o de informa√ß√µes irrelevantes
   ```python
   def _clean_endereco(self, endereco_bruto):
       padroes_a_remover = [
           r'avalia√ß√£o:\s*R\$[^A-Z]*',
           r'Valor m√≠nimo de venda:[^A-Z]*',
           r'desconto de[^A-Z]*',
           r'Apartamento\s*-\s*\d+\s*quarto\(s\)\s*-[^A-Z]*'
       ]
       for padrao in padroes_a_remover:
           endereco = re.sub(padrao, '', endereco, flags=re.IGNORECASE)
   ```

9. **Recupera√ß√£o de Falhas**: Retry inteligente com backoff exponencial
   ```python
   @retry(reraise=True,
          stop=stop_after_attempt(5),
          wait=wait_exponential(multiplier=0.5, min=0.5, max=6),
          retry=retry_if_exception_type(RequestException))
   def _post(self, url: str, data: dict):
       # Detec√ß√£o autom√°tica de falhas e retry
   ```

10. **Estruturas Inconsistentes**: M√∫ltiplos parsers e fallbacks
    ```python
    def extract_imoveis_from_page(self, html_content):
        # Estrat√©gia principal
        results_section = soup.find('div', id='listaimoveispaginacao')
        if results_section:
            property_items = results_section.find_all('li', class_='group-block-item')
        else:
            # M√©todos alternativos
            imoveis = self._extract_from_fallback_methods(soup)
    ```

11. **Simula√ß√£o Humana**: Headers completos + timing natural
    ```python
    s.headers.update({
        "User-Agent": self.ua.random,
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9",
        "Accept-Language": "pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7",
        "Connection": "keep-alive",
        "Referer": self.search_url,
        "Origin": BASE_URL
    })
    # Primeira visita para estabelecer sess√£o
    s.get(self.search_url, timeout=30)
    ```

12. **Debugging**: Logging abrangente + salvamento de HTML
    ```python
    def debug_save_html(self, html_content, filename="debug_page.html"):
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(html_content)
        logger.info(f"HTML salvo para debug: {filename}")
    
    @log_method  # Decorator para logging autom√°tico
    def scrapeImoveis(self):
        logger.info("üìä Pagina√ß√£o detectada:")
        logger.info(f"   Total de p√°ginas: {total_paginas}")
